# -*- coding: utf-8 -*-
"""AppleStockPredictionLSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1trsvNXl5NQ_MAdSrCBsCgOwjHn8YmP_4

# Stock price prediction using LSTM
LSTM (Long Short-Term Memory) is a type of Recurrent Neural Network (RNN) architecture designed to handle sequence data and overcome the limitations of traditional RNNs. Will predict stock Price of AAPL(Apple) using LSTM.

* **1.) Explore change in price of the stock over time**
* **2.) Explore the daily return of the stock on average**
* **3.) Check the moving average of the various stocks**
* **4.) Check the correlation between different stocks**
* **5.) Evaluate the value at risk by investing in a particular stock**
* **6.) Predict future stock behavior? (Predicting the closing price stock price of APPLE inc using LSTM)**

# **Step 1 - Importing the libraries**

```
# This is formatted as code
```

**Configuration Libraries**
"""

import warnings
from datetime import datetime
warnings.filterwarnings("ignore")

"""**Common Libraries**"""

#@title import numpy pandas seaborn matplotlib and plotly
import numpy as np
import pandas as pd
import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt
import plotly.io as pio

"""**Machine Learning Libraries**"""

#@title Import Keras and sklearn
from sklearn.metrics import *
from keras.layers import LSTM
from keras.layers import Dense
from keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler
# from keras.preprocessing.sequence import TimeseriesGenerator

"""**Stock API**

* **Here we are using yfinance: https://pypi.org/project/yfinance/**
* **Ticker symbol docs: https://www.nasdaq.com/market-activity/stocks/screener**
"""

#@title Install kaleido library
!pip install -U kaleido

!pip install yfinance
import yfinance as yf

"""**Grabbing data from YFINANCE**"""

data = yf.Ticker("AAPL") # For Apple stock

hist = data.history(period = "1mo")

data.info

"""**Converting values into dataframe**"""

current_date = datetime.now()
start_date = datetime(current_date.year - 1, current_date.month, current_date.day)

data = yf.download("AAPL", start_date, current_date)

"""**Data**"""

data.head()
data.columns = [f"{col[0]}" for col in data.columns]

data.head()

data.tail()

"""**Visualizing the data columns to get a better overview**"""

fig = px.line(data, x=data.index, y="Close", title='Apple Closing Prices')
fig.show()

# @title Histogram on Close price

from matplotlib import pyplot as plt
data['Close'].plot(kind='hist', bins=20, title='Close')
plt.gca().spines[['top', 'right',]].set_visible(False)

"""<hr>

**Data Information**
"""

data.info()

"""* **Need to work with the date columns**
* **Moreover, on the weekends since the markets are closed, hence we need to check for that as well.**

**Data Description**
"""

data.describe()

"""# **Step 2 - Information on Closing Prices**"""

plt.figure(figsize=(15,6))
plt.plot(data.Close, color = "red")
plt.title("Apple Stock Price")
plt.xlabel("Days")
plt.ylabel("Price")
plt.show()

"""# **Step 3 - Information on the volumn of the assest sold**
  * **It is the number / quantity of assests sold or traded between daily open and close**
"""

plt.figure(figsize=(15,6))
plt.plot(data.Volume, color = "blue")
plt.title("Sales Volume of Apple")
plt.xlabel("Date")
plt.ylabel("Volume")
plt.show()

"""<hr>

# **Step 4 - Working with Moving Average**
  * **This will help us find out the updates that were done according to the specified timeframe**

**Finding the MA for the data**
"""

moving_average = [10, 20, 50]

for x in moving_average:
  column_name = f"MA for {x} days"
  data[column_name] = data["Close"].rolling(window = x).mean()

"""**Visualizing the same**"""

fig = px.line(data, x=data.index, y=["Close", "MA for 10 days", "MA for 20 days", "MA for 50 days"],
              title="Moving Average for Apple Closing Prices")
fig.show()

"""**Based on the graph we can say**
  * **The MA taken for 50 days is not able to give us the complete information about the trends, it too smooth with respect to the data**
  * **If we look on to 10 or 20 days MA data, it seems more promising as it captures more information into it**

  * **`We can move forward with MA data having average rolled between 10 or 20 days (Recommendation : 10 days seems more promising)`**

# **Step 5 - Daily Returns of the stock on based on average**
  * **This will let us understand the risk associated with investing in each stock. So, to judge that we have to look onto the daily changes happening with the stock, here absolution won't work**

* **Need to calculate by how much the stocks are changing on daily basis**
"""

data["Daily Returns"] = data["Close"].pct_change()

"""* **Trying to see the percentage changes over the period of time**"""

fig = px.line(data, x = data.index, y = "Daily Returns",
              title = "Change in stocks")
fig.show()

"""**So, here is clear that we are having fluctuations in the terms of change of the close price on daily basis. Trying to take a better look using histogram**"""

fig = px.histogram(data, x = "Daily Returns",
              title = "Change in stocks")
fig.show()

"""<hr>

# **Step 6 - How much is the risk in investment**
"""

risk_df = pd.DataFrame(data["Adj Close"].pct_change().dropna())

area = np.pi * 20

plt.figure(figsize=(10, 8))
plt.scatter(risk_df.mean(), risk_df.std(), s=area)
plt.xlabel('Expected return')
plt.ylabel('Risk')

for label, x, y in zip(risk_df, risk_df.mean(), risk_df.std()):
    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom',
                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))

"""<hr>

# **Step 7 - Working with the training and testing data**
"""

data = yf.download("AAPL", start = "2014-01-01", end = datetime.now())

data.head()
data.columns = [f"{col[0]}" for col in data.columns]

fig = px.line(data, x = data.index, y = "Close", title = "Close Price for Apple in Dollars ($)")
fig.show()

"""**Creating a seperate dataframe that only has Close columns so that we can focus on that only**"""

df_close = data[["Close"]]

len(df_close)

"""**Grabbing the number of rows that we need to train**"""

train_len = int(np.ceil(len(df_close) * 0.95))

train_len

"""<hr>

# **Step 8 - Working with the predictions on the data**

* **Scaling the values**
  * **It's should to be done seperately on the training and testing data, but since we are practicing right now it's fine. Otherwise look-ahead-bias issue can be there**
"""

scaler = MinMaxScaler()

data_scaled = scaler.fit_transform(df_close)

# commonly we would have done something like this
# train_data = scaler.fit_transform(train_data)

pd.DataFrame(data_scaled, columns = ["Scaled Data"])

"""# **Step 9 - Splitting the data into training and testing**

* **We need to create the training data**
"""

train_data = data_scaled[0:train_len, :]

"""* **Splitting the data into training and testing part**"""

x_train, y_train = [], []

# This loop is creating sequences of 60 data points each from the training data.
# Each sequence represents the past 60 values.
for i in range(60, len(train_data)):
  x_train.append(train_data[i-60 : i, 0])
  y_train.append(train_data[i, 0])

# Converting the both in array format for usability
x_train, y_train = np.array(x_train), np.array(y_train)

# Reshaping the data
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

"""# **LSTM Neural Network**

# **Step 10 - Working with Neural Net**
"""

model = Sequential()
model.add(LSTM(128,
               return_sequences = True,
               input_shape = (x_train.shape[1], 1)))
model.add(LSTM(64, return_sequences = False))
model.add(Dense(30))
model.add(Dense(1))

"""**Compilation**"""

model.compile(optimizer = "adam", loss = "mean_squared_error")

"""**Fitting the data**"""

model.fit(x_train, y_train, batch_size = 1, epochs = 2)

"""**Testing data creation**"""

test_data = data_scaled[train_len - 60:, :]

"""* **Creating the subsets of testing**"""

x_test = []
y_test = df_close.values[train_len:, :]

"""* **Creating a sequence of testing data**"""

for i in range(60, len(test_data)):
  x_test.append(test_data[i-60:i, 0])

# Converting x_test to array
x_test = np.array(x_test)

# Reshaping for predictions
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

"""**Predictions**"""

predictions = model.predict(x_test)

predictions = scaler.inverse_transform(predictions)

"""**Evaluations**"""

RMSE = np.sqrt(np.mean((y_test - predictions)**2))

print(f"RMSE: {RMSE}")

"""# **Step 11 - Visualize**"""

# We have two different data's that is training and testing
train = df_close[ : train_len]

prediction_data = df_close[train_len: ]

prediction_data["Predictions"] = predictions

a = prediction_data["Close"].values

b = prediction_data["Predictions"].values

fig = px.line(train, x=train.index, y= "Close", title = "Final Analysis for Apple")
fig.add_scatter(x=prediction_data.index, y= a, name = "Actual")
fig.add_scatter(x=prediction_data.index, y= b, name = "Predictions")
fig.show()

prediction_data.head()

def evaluate(y_test = y_test, prediction = predictions):
  mse = mean_squared_error(y_test, predictions)
  print("Mean squared error:", mse)
  mae = mean_absolute_error(y_test, predictions)
  print("Mean absolute error:", mae)
  r2 = r2_score(y_test, predictions)
  print("R-squared score:", r2)
  RMSE = np.sqrt(np.mean((y_test - predictions)**2))
  print(f"RMSE: {RMSE}")

evaluate()

"""# Make a Python function to predict stock price using ML
* **1.) Download last 1 month stock price from yFinance for a given stock **
* **2.) Data preprocessing**
* **3.) Prepare train-test dataset**
* **4.) Run the model and predict Stock price**
* **5.) Calculate accuracy of that model and plot actual-expected stock price**
"""

#@title Define the function for stock prediction based on last 1 year data
def predict_stock_price(ticker, epochs = 2):
  data = yf.download(ticker, start = "2014-01-01", end = datetime.now())
  df_close = data[["Close"]]
  train_len = int(np.ceil(len(df_close) * 0.95))
  scaler = MinMaxScaler()
  data_scaled = scaler.fit_transform(df_close)
  train_data = data_scaled[0:train_len, :]
  x_train, y_train = [], []
  # This loop is creating sequences of 60 data points each from the training data.
  # Each sequence represents the past 60 values.
  for i in range(60, len(train_data)):
    x_train.append(train_data[i-60 : i, 0])
    y_train.append(train_data[i, 0])
  # Converting the both in array format for usability
  x_train, y_train = np.array(x_train), np.array(y_train)
  # Reshaping the data
  x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
  model = Sequential()
  model.add(LSTM(128,
                return_sequences = True,
                input_shape = (x_train.shape[1], 1)))
  model.add(LSTM(64, return_sequences = False))
  model.add(Dense(30))
  model.add(Dense(1))
  model.compile(optimizer = "adam", loss = "mean_squared_error")
  model.fit(x_train, y_train, batch_size = 1, epochs = epochs)
  test_data = data_scaled[train_len - 60:, :]
  x_test = []
  y_test = df_close.values[train_len:, :]
  for i in range(60, len(test_data)):
    x_test.append(test_data[i-60:i, 0])
  # Converting x_test to array
  x_test = np.array(x_test)
  # Reshaping for predictions
  x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))
  predictions = model.predict(x_test)
  predictions = scaler.inverse_transform(predictions)
  # Evaluation
  RMSE = np.sqrt(np.mean((y_test - predictions)**2))
  print(f"RMSE: {RMSE}")
  # Visualization
  # We have two different data's that is training and testing
  train = df_close[ : train_len]
  prediction_data = df_close[train_len: ]
  prediction_data["Predictions"] = predictions
  a = prediction_data["Close"].values
  b = prediction_data["Predictions"].values
  print(f"Final Analysis for {ticker}")
  print(f"Size of training data: {len(train)}")
  print(f"Size of testing data: {len(prediction_data)}")
  print(f"Size of a: {len(a)} Size of b: {len(b)}")
  #Print the mean value of a and b
  print(f"Mean value of a: {a.squeeze().mean()} Mean value of b: {b.mean()}")
  # Print RMSE as a percentage of mean value of the actual price a
  print(f"RMSE as a percentage of mean value of the actual price: {RMSE/a.squeeze().mean()*100}%")
  # print the first and last element of both train.index and prediction_data.index
  print(f"first and last element of train.index: {train.index[0]} {train.index[-1]}")
  print(f"first and last element of prediction_data.index: {prediction_data.index[0]} {prediction_data.index[-1]}")
  #print(f"train.index: {train.index}")
  #print(f"prediction_data.index: {prediction_data.index}")
  # Print value of actual data a and prediction data b
  #print(f"Actual data: {a.squeeze()}")
  #print(f"Prediction data: {b}")
  # print first and last elemnt of a and b
  print(f"First element of a: {a.squeeze()[0]} Last element of a: {a.squeeze()[-1]}")
  print(f"First element of b: {b[0]} Last element of b: {b[-1]}")

  # Change here: Squeeze the 'Close' column to ensure it's 1D
  fig = px.line(train, x=train.index, y=train["Close"].squeeze(), title=f"Final Analysis for {ticker}")
  fig.add_scatter(x=prediction_data.index, y=a.squeeze(), name="Actual")
  fig.add_scatter(x=prediction_data.index, y=b, name="Predictions")
  fig.show()
  # Set the width and height for the saved image
  #fig.update_layout(width=1920, height=1080)
  # Use the 'svg' format for maximum quality when zooming
  pio.write_image(fig, f"{ticker}_pred.pdf", scale=6, width=1080, height=1080)
  result_dict = dict()
  result_dict["RMSE"] = RMSE
  result_dict["training_data_size"] = len(train)
  result_dict["testing_data_size"] = len(prediction_data)
  result_dict["stock_price_mean"] = a.squeeze().mean()
  result_dict["prediction_price_mean"] = b.mean()
  result_dict["percentage_RMSE"] = RMSE/a.squeeze().mean()*100
  result_dict["train_duration"] = [train.index[0], train.index[-1]]
  result_dict["prediction_duration"] = [prediction_data.index[0], prediction_data.index[-1]]
  result_dict["fig"] = fig
  return result_dict

#@title Call this function for Microsoft ticker MSFT
result_microsoft = predict_stock_price("MSFT", epochs = 10)

#@title Call this function for Amazon ticker
result_amazon = predict_stock_price("AMZN", epochs = 10)

#@title Call this function for Meta facebook ticker
result_meta = predict_stock_price("META", epochs = 10)

#@title Call this function for Alaphabet Google ticker
result_google = predict_stock_price("GOOG", epochs= 10)

#@title Call this function for Netflix ticker
result_netflix=predict_stock_price("NFLX", epochs= 10)

#@title Call this function for Apple ticker
result_apple = predict_stock_price("AAPL", epochs= 10)